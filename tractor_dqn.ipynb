{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd057baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\utils\\utils.py:335: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\models\\tractor_pretrained_models.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\models\\tractor_pretrained_models.py:87: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:281: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:298: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\RanW\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\RanW\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:323: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:284: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:284: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:284: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:286: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\agents\\dqn_agent.py:289: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:From d:\\Projects\\rlcard\\rlcard\\models\\tractor_pretrained_models.py:114: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from d:\\Projects\\rlcard\\rlcard\\models\\tractorV7\\tractor_dqn_1430k_best_779\\model\n",
      "[<rlcard.agents.dqn_agent.DQNAgent object at 0x000002549189B308>, <rlcard.agents.dqn_agent.DQNAgent object at 0x00000254B19C4E08>]\n",
      "INFO:tensorflow:Restoring parameters from d:\\Projects\\rlcard\\rlcard\\models\\tractorV7\\tractor_dqn_2000k_best_769\\model\n",
      "[<rlcard.agents.dqn_agent.DQNAgent object at 0x00000254B1C85788>, <rlcard.agents.dqn_agent.DQNAgent object at 0x00000254B60D9C48>]\n"
     ]
    }
   ],
   "source": [
    "import rlcard\n",
    "from rlcard.utils import set_global_seed\n",
    "from rlcard import models\n",
    "\n",
    "# Make environment\n",
    "env = rlcard.make('tractor', config={'seed': 0})\n",
    "\n",
    "# Set a global seed\n",
    "set_global_seed(0)\n",
    "\n",
    "dqn_agents = models.load('tractor_dqn_v1').agents\n",
    "print(dqn_agents)\n",
    "\n",
    "dqn_vnext_agents = models.load('tractor_dqn_vnext').agents\n",
    "print(dqn_vnext_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rlcard.games.tractor.utils import CARD_RANK_STR, ACTION_LIST\n",
    "from rlcard.agents import RandomAgent, TractorRuleAgent\n",
    "\n",
    "# Evaluate the performance. Play with random agents.\n",
    "random_agent = RandomAgent(env.action_num)\n",
    "rule_agent = TractorRuleAgent(env.action_num)\n",
    "\n",
    "# env.set_agents([rule_agent, rule_agent, rule_agent, rule_agent])\n",
    "\n",
    "# env.set_agents([dqn_agents[0], random_agent, dqn_agents[0], random_agent])\n",
    "# env.set_agents([dqn_agents[0], dqn_agents[0], dqn_agents[0], dqn_agents[0]])\n",
    "\n",
    "# env.set_agents([dqn_agents[0], rule_agent, dqn_agents[0], rule_agent])\n",
    "# env.set_agents([rule_agent, dqn_agents[0], rule_agent, dqn_agents[0]])\n",
    "# env.set_agents([dqn_vnext_agents[0], rule_agent, dqn_vnext_agents[0], rule_agent])\n",
    "# env.set_agents([rule_agent, dqn_vnext_agents[1], rule_agent, dqn_vnext_agents[1]])\n",
    "\n",
    "\n",
    "# env.set_agents([dqn_agents[0], dqn_vnext_agents[0], dqn_agents[0], dqn_vnext_agents[0]])\n",
    "# env.set_agents([dqn_agents[0], dqn_vnext_agents[1], dqn_agents[0], dqn_vnext_agents[1]])\n",
    "\n",
    "\n",
    "env.set_agents([dqn_agents[0], dqn_agents[1], dqn_agents[0], dqn_agents[1]])\n",
    "# env.set_agents([dqn_vnext_agents[0], dqn_agents[1], dqn_vnext_agents[0], dqn_agents[1]])\n",
    "# env.set_agents([dqn_vnext_agents[0], dqn_vnext_agents[1], dqn_vnext_agents[0], dqn_vnext_agents[1]])\n",
    "\n",
    "# env.set_agents([rule_agent, random_agent, rule_agent, random_agent])\n",
    "\n",
    "# predefined_hands = [['AH', '3H'],\n",
    "#                     ['3H', 'QH'],\n",
    "#                     ['4H', '5H'],\n",
    "#                     ['7H', '6H']]\n",
    "\n",
    "# state = env.reset_predefine_state(predefined_hands)\n",
    "state, player_id = env.reset()\n",
    "# action = env.agents[player_id].step(state)\n",
    "# state, player_id = env.step(action, env.agents[player_id].use_raw)\n",
    "\n",
    "# for i in range(4):\n",
    "#     print(env.game.players[i].current_hand)\n",
    "\n",
    "# for j in range(3):\n",
    "#     for k in range(72):\n",
    "#         for i in range(9):\n",
    "#             print(state['obs'][i][j][k], end = ',')\n",
    "#     print()\n",
    "\n",
    "# print(state)\n",
    "# q = env.agents[1].eval_step(state)[1]\n",
    "# print(len(q))\n",
    "# probs = {i:round(q[i],3) for i in range(len(q)) if q[i] != -10000}\n",
    "# print(probs)\n",
    "\n",
    "\n",
    "# probs = {ACTION_LIST[i]:round(q[i],3) for i in range(len(q)) if q[i] != -10000}\n",
    "# probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(str(probs))\n",
    "\n",
    "_trajectories, _payoffs = env.run(is_training=False, debug=True)\n",
    "\n",
    "# print(\"remaining cards:\")\n",
    "# print(env.game.round.remaining_cards)\n",
    "\n",
    "# print()\n",
    "# print(env.game.judger.trump)\n",
    "\n",
    "output = []\n",
    "for i in range(10):\n",
    "    for j in range(3):\n",
    "        for k in range(72):\n",
    "            print(_trajectories[0][20][0]['obs'][i][j][k], end = ',')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in probs:\n",
    "    # print(\"Assert.AreEqual({}m, Math.Round(output[{}], 3));\".format(probs[key], key))\n",
    "    print(\"Assert.IsTrue(Math.Abs({} - output[{}]) < 1e-3);\".format(probs[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.games.tractor.utils import tournament_tractor\n",
    "from rlcard.agents import TractorRuleAgent\n",
    "\n",
    "rule_agent = TractorRuleAgent(env.action_num)\n",
    "\n",
    "evaluate_num = 1000\n",
    "env.set_agents([dqn_vnext_agents[0], rule_agent, dqn_vnext_agents[0], rule_agent])\n",
    "reward = tournament_tractor(env, evaluate_num)\n",
    "print('Average win rate: ', reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rlcard.games.tractor.utils import CARD_RANK_STR, ACTION_LIST\n",
    "\n",
    "for i in range(len(_trajectories[0])):\n",
    "    print(\"Round {}:\".format(i))\n",
    "\n",
    "    for p in range(4):\n",
    "        cards = []\n",
    "        for j in range(len(CARD_RANK_STR)):\n",
    "            if _trajectories[0][i][0]['obs'][p][1][j] == 1:\n",
    "                cards.append(CARD_RANK_STR[j])\n",
    "            if _trajectories[0][i][0]['obs'][p][2][j] == 1:\n",
    "                cards.append(CARD_RANK_STR[j])\n",
    "                cards.append(CARD_RANK_STR[j])\n",
    "        # print(','.join(cards))\n",
    "    print('Action: {}'.format(ACTION_LIST[_trajectories[0][i][1]]))\n",
    "    print(env.game.round.trace[i*4:(i+1)*4])\n",
    "    # print(\"Score: {} : {}\".format(_trajectories[0][i][0]['obs'][5][0][0], _trajectories[0][i][0]['obs'][5][0][1]))\n",
    "    print()\n",
    "\n",
    "print(env.game.round.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Evaluating 4999/5000 episodes...Average win rate (base vs base):  [0.2178, 0.7822, 0.2178, 0.7822]\n",
      "\n",
      "Evaluating 4999/5000 episodes...Average win rate (next vs base):  [0.226, 0.774, 0.226, 0.774]\n",
      "\n",
      "Evaluating 4999/5000 episodes...Average win rate (base vs next):  [0.2144, 0.7856, 0.2144, 0.7856]\n"
     ]
    }
   ],
   "source": [
    "from rlcard.games.tractor.utils import tournament_tractor\n",
    "evaluate_num = 5000\n",
    "\n",
    "env.set_agents([dqn_agents[0], dqn_agents[1], dqn_agents[0], dqn_agents[1]])\n",
    "reward = tournament_tractor(env, evaluate_num)\n",
    "print('Average win rate (base vs base): ', reward)\n",
    "\n",
    "env.set_agents([dqn_vnext_agents[0], dqn_agents[1], dqn_vnext_agents[0], dqn_agents[1]])\n",
    "reward = tournament_tractor(env, evaluate_num)\n",
    "print('Average win rate (next vs base): ', reward)\n",
    "\n",
    "env.set_agents([dqn_agents[0], dqn_vnext_agents[1], dqn_agents[0], dqn_vnext_agents[1]])\n",
    "reward = tournament_tractor(env, evaluate_num)\n",
    "print('Average win rate (base vs next): ', reward)\n",
    "\n",
    "# env.set_agents([dqn_vnext_agents[0], dqn_vnext_agents[1], dqn_vnext_agents[0], dqn_vnext_agents[1]])\n",
    "# reward = tournament_tractor(env, evaluate_num)\n",
    "# print('Average win rate (next vs next): ', reward)"
   ]
  },
  {
   "source": [
    "tractor_dqn_1430k vs tractor_dqn_1430k_best_779\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (base vs base):  [0.218, 0.782, 0.218, 0.782]\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (next vs base):  [0.2216, 0.7784, 0.2216, 0.7784]\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (base vs next):  [0.2208, 0.7792, 0.2208, 0.7792]\n",
    "\n",
    "\n",
    "tractor_dqn_1430k_best_779 vs tractor_dqn_2000k_best_769\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (base vs base):  [0.2178, 0.7822, 0.2178, 0.7822]\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (next vs base):  [0.226, 0.774, 0.226, 0.774]\n",
    "\n",
    "Evaluating 4999/5000 episodes...Average win rate (base vs next):  [0.2144, 0.7856, 0.2144, 0.7856]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}